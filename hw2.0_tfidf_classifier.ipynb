{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 - TF-IDF Classifier\n",
    "\n",
    "Ваша цель обучить классификатор который будет находить \"токсичные\" комментарии и опубликовать решения на Kaggle [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)\n",
    "\n",
    "В процессе обучения нужно ответить на ***[вопросы](https://docs.google.com/forms/d/e/1FAIpQLSd9mQx8EFpSH6FhCy1M_FmISzy3lhgyyqV3TN0pmtop7slmTA/viewform?usp=sf_link)***\n",
    "\n",
    "Данные можно скачать тут - https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train = pd.read_csv('train.csv').fillna(' ')\n",
    "test = pd.read_csv('test.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стадартными подходами для анализа текста являются [Bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model) и его модификация [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf).\n",
    "\n",
    "Они реалзованны в `sklearn` в виде [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) и [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n",
    "\n",
    "Более подробней про них можно посмотреть [тут](https://github.com/udsclub/workshop/blob/master/notebooks/UDS-workshop-feature-extraction-and-engineering.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def other_info(data):\n",
    "#Letter count\n",
    "    data['count_letters']=data[\"comment_text\"].apply(lambda x: len(str(x)))\n",
    "#Average length of the words\n",
    "    data[\"mean_word_len\"] = data[\"comment_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "    data['word_unique_percent']=(data[\"comment_text\"].apply(lambda x: len(set(str(x).split()))))*100/(data[\"comment_text\"].apply(lambda x: len(str(x).split())))\n",
    "    \n",
    "    data.loc[data['count_letters']>1000, 'count_letters'] = 1000\n",
    "    data.loc[data['mean_word_len']>100, 'mean_word_len'] = 100\n",
    "    \n",
    "    smileys_good = r'((:|;|X)-?(\\)|P|D))\\W'\n",
    "    smileys_bad =  r'((:|;)-?(\\())\\W'\n",
    "    data['smileys_good'] = data['comment_text'].str.extract(smileys_good, expand=True)[0].fillna(0)\n",
    "    data['smileys_bad'] = data['comment_text'].str.extract(smileys_bad, expand=True)[0].fillna(0)\n",
    "    data['smileys_good'][data['smileys_good']!=0] = 1\n",
    "    data['smileys_bad'][data['smileys_bad']!=0] = 1\n",
    "    \n",
    "       \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "E:\\Python\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "E:\\Python\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train = other_info(train)\n",
    "test = other_info(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>count_letters</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>word_unique_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>367</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>84.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>50</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>54</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>205</td>\n",
       "      <td>4.421053</td>\n",
       "      <td>78.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>41</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "   count_letters  mean_word_len  word_unique_percent  \n",
       "0            367       4.111111            84.722222  \n",
       "1             50       3.000000            91.666667  \n",
       "2             54       2.916667            83.333333  \n",
       "3            205       4.421053            78.947368  \n",
       "4             41       5.000000           100.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>count_letters</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>word_unique_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>316.677084</td>\n",
       "      <td>4.888781</td>\n",
       "      <td>85.501925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>294.397262</td>\n",
       "      <td>1.875908</td>\n",
       "      <td>12.817618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>4.330472</td>\n",
       "      <td>77.906977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>4.696429</td>\n",
       "      <td>87.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>5.105263</td>\n",
       "      <td>95.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  count_letters  mean_word_len  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.049364       0.008805     316.677084       4.888781   \n",
       "std         0.216627       0.093420     294.397262       1.875908   \n",
       "min         0.000000       0.000000       6.000000       1.000000   \n",
       "25%         0.000000       0.000000      96.000000       4.330472   \n",
       "50%         0.000000       0.000000     205.000000       4.696429   \n",
       "75%         0.000000       0.000000     435.000000       5.105263   \n",
       "max         1.000000       1.000000    1000.000000     100.000000   \n",
       "\n",
       "       word_unique_percent  \n",
       "count        159571.000000  \n",
       "mean             85.501925  \n",
       "std              12.817618  \n",
       "min               0.080000  \n",
       "25%              77.906977  \n",
       "50%              87.500000  \n",
       "75%              95.652174  \n",
       "max             100.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter(\" \".join(all_text).split()).most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#text = pd.Series(' '.join(all_text).split())\n",
    "#words = pd.Series(text.str.lower().str.split('\\s+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    min_df=4,\n",
    "    ngram_range=(1,2),\n",
    "    max_features=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#word_vectorizer_cv = CountVectorizer(max_features=50000, analyzer='word', stop_words='english',ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для классификации будем использовать логистическую регрессию [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'C': (0.1, 0.3, 0.5, 0.7, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state=17, class_weight= 'balanced') # Попробуйте разные параметры, найтдите оттимальные на кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_lr = GridSearchCV(classifier, parameters, n_jobs=-1, scoring ='roc_auc', verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    \n",
    "    gs_lr.fit(train_word_features,train[class_name])\n",
    "\n",
    "    gs_score = gs_lr.best_params_\n",
    "    \n",
    "    print('CV score for class {} is {}'.format(class_name, gs_score))\n",
    "    scores.append(cv_score)\n",
    "\n",
    "print('Total score is {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_C = LogisticRegression(C=1, random_state=17, class_weight= 'balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем тренировать по одному классификатору на каждый класс. \n",
    "\n",
    "Что бы провалидировать качество модели воспользуемся функцией [cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.9700999951598369\n",
      "CV score for class severe_toxic is 0.9856283535366693\n",
      "CV score for class obscene is 0.9855489461075196\n",
      "CV score for class threat is 0.98233574651186\n",
      "CV score for class insult is 0.9773422785912181\n",
      "CV score for class identity_hate is 0.9742847166463339\n",
      "Total score is 0.9792066727589064\n"
     ]
    }
   ],
   "source": [
    "scores= []\n",
    "\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier_C, train_word_features, train_target, scoring='roc_auc'))\n",
    "    \n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "    scores.append(cv_score)\n",
    "\n",
    "print('Total score is {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте подобрать лучшие параметры для `word_vectorizer` и `classifier` оптимизируя метрику [ROC AUC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectorizer_2 = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    min_df=4,\n",
    "    ngram_range=(2,5),\n",
    "    max_features=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectorizer_2.fit(all_text)\n",
    "train_word_features_2 = word_vectorizer_2.transform(train_text)\n",
    "test_word_features_2 = word_vectorizer_2.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores= []\n",
    "\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier_C, train_word_features_2, train_target, scoring='roc_auc'))\n",
    "    \n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "    scores.append(cv_score)\n",
    "\n",
    "print('Total score is {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectorizer_3 = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    stop_words='english',\n",
    "    min_df=4,\n",
    "    ngram_range=(2,3),\n",
    "    max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectorizer_3.fit(all_text)\n",
    "train_word_features_3 = word_vectorizer_3.transform(train_text)\n",
    "test_word_features_3 = word_vectorizer_3.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classifier_2 = LogisticRegression(C=1, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.7804504696023375\n",
      "CV score for class severe_toxic is 0.8563472309459356\n",
      "CV score for class obscene is 0.7998012898538324\n",
      "CV score for class threat is 0.7811913766015661\n",
      "CV score for class insult is 0.8000544626872695\n",
      "CV score for class identity_hate is 0.7801227647846734\n",
      "Total score is 0.7996612657459358\n"
     ]
    }
   ],
   "source": [
    "scores= []\n",
    "\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier_C, train_word_features_3, train_target, scoring='roc_auc'))\n",
    "    \n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "    scores.append(cv_score)\n",
    "\n",
    "print('Total score is {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features_two = hstack([train_word_features_3, train_word_features])\n",
    "test_features_two = hstack([test_word_features_3, test_word_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.9659046666045944\n",
      "CV score for class severe_toxic is 0.9837634175869231\n",
      "CV score for class obscene is 0.9830527903952441\n",
      "CV score for class threat is 0.97893755156244\n",
      "CV score for class insult is 0.9739593594191519\n",
      "CV score for class identity_hate is 0.9712561119086517\n",
      "Total score is 0.9761456495795008\n"
     ]
    }
   ],
   "source": [
    "scores= []\n",
    "\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier_C, train_features_two, train_target, scoring='roc_auc'))\n",
    "    \n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "    scores.append(cv_score)\n",
    "\n",
    "print('Total score is {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вторя модель логрег"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate', 'count_letters', 'mean_word_len',\n",
       "       'word_unique_percent', 'smileys_good', 'smileys_bad'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_features = ['count_letters', 'mean_word_len', 'word_unique_percent', 'smileys_good', 'smileys_bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_log = LogisticRegression(C=10, random_state=17, class_weight= 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_other = train[add_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ither = test[add_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ither = test_ither.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.6239167550695873\n",
      "CV score for class severe_toxic is 0.7113087040000794\n",
      "CV score for class obscene is 0.6420780659718605\n",
      "CV score for class threat is 0.696392783583883\n",
      "CV score for class insult is 0.6416188095614094\n",
      "CV score for class identity_hate is 0.6304301398000071\n",
      "Total score is 0.6576242096644711\n"
     ]
    }
   ],
   "source": [
    "scores= []\n",
    "\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier_log, train_other, train_target, scoring='roc_auc'))\n",
    "    \n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "    scores.append(cv_score)\n",
    "\n",
    "print('Total score is {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission2 = pd.DataFrame.from_dict({'id': test['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    classifier_log.fit(train_other, train_target)\n",
    "    ...\n",
    "    submission2[class_name] = classifier_log.predict_proba(test_ither)[:, 1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission2.to_csv('submission_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.458662</td>\n",
       "      <td>0.355049</td>\n",
       "      <td>0.444065</td>\n",
       "      <td>0.394614</td>\n",
       "      <td>0.438345</td>\n",
       "      <td>0.442375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.596920</td>\n",
       "      <td>0.616940</td>\n",
       "      <td>0.607758</td>\n",
       "      <td>0.619074</td>\n",
       "      <td>0.609621</td>\n",
       "      <td>0.585009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.631529</td>\n",
       "      <td>0.723695</td>\n",
       "      <td>0.651710</td>\n",
       "      <td>0.714960</td>\n",
       "      <td>0.655163</td>\n",
       "      <td>0.633776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.570393</td>\n",
       "      <td>0.637813</td>\n",
       "      <td>0.581493</td>\n",
       "      <td>0.634573</td>\n",
       "      <td>0.583524</td>\n",
       "      <td>0.580324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.559464</td>\n",
       "      <td>0.527451</td>\n",
       "      <td>0.561440</td>\n",
       "      <td>0.522494</td>\n",
       "      <td>0.564988</td>\n",
       "      <td>0.548044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.458662      0.355049  0.444065  0.394614  0.438345   \n",
       "1  0000247867823ef7  0.596920      0.616940  0.607758  0.619074  0.609621   \n",
       "2  00013b17ad220c46  0.631529      0.723695  0.651710  0.714960  0.655163   \n",
       "3  00017563c3f7919a  0.570393      0.637813  0.581493  0.634573  0.583524   \n",
       "4  00017695ad8997eb  0.559464      0.527451  0.561440  0.522494  0.564988   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.442375  \n",
       "1       0.585009  \n",
       "2       0.633776  \n",
       "3       0.580324  \n",
       "4       0.548044  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опубликуйте лучшие решение на [Kaggle Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({'id': test['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    classifier_C.fit(train_features_two, train_target)\n",
    "    ...\n",
    "    submission[class_name] = classifier_C.predict_proba(test_features_two)[:, 1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>0.771937</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.248973</td>\n",
       "      <td>0.996095</td>\n",
       "      <td>0.943773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.026384</td>\n",
       "      <td>0.008228</td>\n",
       "      <td>0.009832</td>\n",
       "      <td>0.010894</td>\n",
       "      <td>0.024578</td>\n",
       "      <td>0.013407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.098538</td>\n",
       "      <td>0.016102</td>\n",
       "      <td>0.044108</td>\n",
       "      <td>0.006907</td>\n",
       "      <td>0.069139</td>\n",
       "      <td>0.021819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.047892</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>0.002899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.112502</td>\n",
       "      <td>0.019543</td>\n",
       "      <td>0.050670</td>\n",
       "      <td>0.011498</td>\n",
       "      <td>0.142304</td>\n",
       "      <td>0.009334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.999890      0.771937  0.999910  0.248973  0.996095   \n",
       "1  0000247867823ef7  0.026384      0.008228  0.009832  0.010894  0.024578   \n",
       "2  00013b17ad220c46  0.098538      0.016102  0.044108  0.006907  0.069139   \n",
       "3  00017563c3f7919a  0.047892      0.013774  0.008430  0.004627  0.007025   \n",
       "4  00017695ad8997eb  0.112502      0.019543  0.050670  0.011498  0.142304   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.943773  \n",
       "1       0.013407  \n",
       "2       0.021819  \n",
       "3       0.002899  \n",
       "4       0.009334  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_end = submission.merge(submission2, on = \"id\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_end[\"toxic\"] = submission_end[\"toxic_x\"]*0.9+submission_end[\"toxic_y\"]*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_end[\"severe_toxic\"] = submission_end[\"severe_toxic_x\"]*0.9+submission_end[\"severe_toxic_y\"]*0.1\n",
    "submission_end[\"obscene\"] = submission_end[\"obscene_x\"]*0.9+submission_end[\"obscene_y\"]*0.1\n",
    "submission_end[\"threat\"] = submission_end[\"threat_x\"]*0.9+submission_end[\"threat_y\"]*0.1\n",
    "submission_end[\"insult\"] = submission_end[\"insult_x\"]*0.9+submission_end[\"insult_y\"]*0.1\n",
    "submission_end[\"identity_hate\"] = submission_end[\"identity_hate_x\"]*0.9+submission_end[\"identity_hate_y\"]*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'toxic_x', 'severe_toxic_x', 'obscene_x', 'threat_x', 'insult_x',\n",
       "       'identity_hate_x', 'toxic_y', 'severe_toxic_y', 'obscene_y', 'threat_y',\n",
       "       'insult_y', 'identity_hate_y', 'toxic', 'severe_toxic', 'obscene',\n",
       "       'threat', 'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_end.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_end.drop(['toxic_x', 'severe_toxic_x', 'obscene_x', 'threat_x', 'insult_x',\n",
    "       'identity_hate_x', 'toxic_y', 'severe_toxic_y', 'obscene_y', 'threat_y',\n",
    "       'insult_y', 'identity_hate_y'],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_end.to_csv('submission_end.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
